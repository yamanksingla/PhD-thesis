
\begin{enumerate}
    \item 1. The thesis innovatively extends the traditional communication model to a seven-modality framework. However, the formal mathematical definition of how these modalities interact—potentially via a probabilistic graphical model or Bayesian network—could be more rigorously defined.

\item Clarification on the independence assumptions among modalities (e.g., how the “time of effect” is decoupled from the “channel” in the probabilistic model) would strengthen the theoretical foundation.

\item The construction of large-scale datasets for persuasion strategies (including both image and video advertisements) is technically impressive. However, additional details on the entropy-based active learning algorithm are needed. For instance, specifying the entropy threshold, sample selection criteria, and convergence properties would improve reproducibility.


\item Reporting inter-annotator agreement metrics (such as Cohen’s kappa or Fleiss’ kappa) and how they influenced the calibration of the annotation process would provide deeper insights into the quality of the labels.

\item The multi-task attention fusion model is a significant contribution. Yet, the technical specifics—such as the number of layers, attention head configurations, embedding dimensions, and parameter counts—should be explicitly documented.


\item Ablation study quantifying the contribution of each modality (text, image, video, etc.) to the final performance would be valuable, alongside comparisons of different strategies (e.g., early vs. late fusion).


\item The LCBM’s integration of sender, receiver, and temporal information with traditional content features is a novel approach. More technical exposition on the training pipeline is suggested: elaborate on the optimization algorithm, learning rate schedules, batch sizes, and regularization methods (e.g., dropout or weight decay).


\item Given that behavioral datasets are often incomplete, a detailed discussion on handling missing modalities (e.g., using data imputation methods, partial supervision, or multi-task learning techniques) would enhance the technical rigor.


\item The evaluation metrics (e.g., accuracy, F1 score, ROC-AUC for classification tasks; mean squared error for regression tasks) should be defined in context, with clear justification for their selection in behavioral prediction and persuasion strategy tasks.


\item Given the scale of the datasets (e.g., 168 million tweets, 40,000 YouTube videos), an in-depth discussion on computational efficiency is essential. Specify the hardware used (GPUs/TPUs), distributed training strategies, memory management, and overall training time.

\item Addressing techniques for handling large-scale data, such as mini-batch sampling strategies or data parallelism, would enhance the technical robustness of the work.


\item In the chapter on generating content (e.g., using the Henry system for text generation and the Engagement Arena for text-to-image models), the integration of behavioral feedback into the generation process is innovative. Further technical details on the conditioning mechanism (e.g., how behavioral signals are encoded and merged with latent representations) would clarify the method.


\item Given the extensive use of real-world behavioral data, the thesis would benefit from a more technical discussion on bias mitigation strategies—such as fairness-aware learning algorithms—and privacy-preserving techniques (e.g., differential privacy, anonymization protocols).
\end{enumerate}

